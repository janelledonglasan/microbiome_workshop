---
title: "USF Omics Hub Microbiome Data-Analysis Workshop: hands-on exercises"
authors: "J. Oberstaller, A. Sarkar, J. Gibbons, T.E. Keller, S. Rakesh, C. Wang"
guinea-pigs: "J. Donglasan, S. Jahangiri, J. Dahrendorff"
date: "6/09/2020"
output: pdf
---
### First we created a new Rproject in the "Day3" directory using RStudio, which automatically set our home directory to Day3. Now we are ready to run some code!###

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo=TRUE)
source("../Rsource/Hub_microbiome_workshop_source.R")
```

```{r makedir, include=FALSE}
# run the function to make the empty directories we need for our output
makeRdirs()

# remove the function from the environment because we don't need it anymore
#rm(makeRdirs)
```

# USF Omics Hub Microbiome Workshop Day 2: Generating ASV tables from microbiome-sample sequencing data #

# Pipeline-overview #

*Goal*: The purpose of this analysis is to obtain an Amplicon Sequence Variant (ASV) table for all of our microbiome-sample example-data.

*Input data*: We will start with demultiplexed fastq files for all samples. *This analysis is for paired-end data.* Thus, for each sample, there will be two files, named according to Illumina platform conventions:

  1. Forward-reads, named *_R1_001.fastq
  2. Reverse-reads, named *_R2_001.fastq

## Before we begin ##
Before we begin, let's take a moment to get organized. The importance of documentation and good record-keeping are *essential* to producing high-quality and reproducible computational analyses, just as they are at the bench! 

We recommend you keep your analyses organized by project (just as we organized this example). Looking around: 
    
  - **Rdata**: this folder contains our input .fastq.gz files and our input database of 16S-sequences that we'll use to identify taxa present in our samples.

  - **Ranalysis**: this folder contains any scripts we create to analyze our data, like this R-Markdown (.Rmd) document.
  - **Routput**: we will direct any output data-files from our analyses to this folder.
  - **Rfigs**: we will direct any figures we generate from our analyses to this folder.

## Begin analyses ##

Now back to RStudio.

```{r load, include=TRUE, echo=FALSE, warning=FALSE}
# Let's load the appropriate R packages (dada2 and a few others) for the analysis. All packages are already installed.
library(dada2)
library(GUniFrac)
library(simEd)
library(tictoc)
```

*Important:* make sure to note the package-version of each package you're using!
```{r version-check}
packageVersion("dada2")
packageVersion("GUniFrac")
packageVersion("simEd")
packageVersion("tictoc")
```

Next we will load our input-data into R:
```{r}
# Let's give the path to the directory where all the fastq files are stored a name ("demo_microbiome_fasqfiles").
demo_microbiome_fasqfiles <- "Rdata/fastq"
```

```{r separate_fastq_files}
# Check that the fastq directory contains all our fastq files
list.files(demo_microbiome_fasqfiles)
# Now make two variables to separate and store the forward and the reverse reads
demo_F <- sort(list.files(demo_microbiome_fasqfiles,
                          pattern="_R1_001.fastq",
                          full.names = TRUE))
demo_R <- sort(list.files(demo_microbiome_fasqfiles,
                          pattern="_R2_001.fastq",
                          full.names = TRUE))
# Extract filenames of all samples for future steps in the analysis
demo_samplenames <- sapply(strsplit(basename(demo_F),
                                    "_"),
                           '[', 1)
```

## JO NOTE: We'll be moving at a fast pace and you'll be encountering lots of new functions. Remember you can type ?function_name() into the console at any time to get an explanation for what any function does and available options/parameters. The information will be dense, but helpful!


## Evaluating data-quality ##

Let's check our data-quality by making plots and viewing them directly in RStudio. Your plots will appear in the RStudio "Plots" pane to the lower-right.

```{r check_fastq_quality}
# First we'll check the forward-reads:
plotQualityProfile(demo_F[1:4],
                   n=1e+06)
# Now let's plot to check the data-quality of our reverse-reads.
plotQualityProfile(demo_R[1:4],
                   n=1e+06)
```

Let's also output the plots as .pdf files so we can view them later. They'll be saved in the Rfigs directory.
  *Helpful tip: It is important to save any data or figures you generate in R that you want to keep to file; they are not saved when you quit RStudio, and you'll have to regenerate them!*
  
```{r make_quality_pdfs, include=TRUE, echo=FALSE, warning=FALSE}
## save data-quality plot for forward-reads:
pdf("Rfigs/demo_F_quality.pdf",
    width = 12,
    height = 8,
    pointsize = 8)
plotQualityProfile(demo_F[1:4],
                   n=1e+06)
dev.off()
# save the data-quality plot for our reverse-reads:
pdf("Rfigs/demo_R_quality.pdf",
    width = 12,
    height = 8,
    pointsize = 8)
plotQualityProfile(demo_R[1:4],
                   n=1e+06)
dev.off()
```

## Filter reads based on data-quality ##

The next step is to filter the sequences appropriately, the parameters for which will depend on the data. 

Conceptually, we will discard the bad reads, trim the ends of the good reads, and then save the trimmed good reads to a new directory.

First we will specify the path and name the output-files to which the good sequences will be written. 
  **the directory and output-files we specify here will be created in the next step (filterAndTrim).**
```{r filter_bad_reads1}
# The first step here is to specify the path and name the output-files to which the good sequences will be written. 
  # the directory and output-files we specify here will be created in the next step (filterAndTrim).

## JO NOTE: remove references to the "here" package; instead begin tutorial with how to set up a project in RStudio
demo_goodF <- file.path("Routput/demo_good_filtered",
                        paste0(demo_samplenames,
                               "F_good.fastq.gz"))
demo_goodR <- file.path("Routput/demo_good_filtered",
                        paste0(demo_samplenames,
                               "R_good.fastq.gz"))
names(demo_goodF) <- demo_samplenames
names(demo_goodR) <- demo_samplenames
```


Now we perform the very important step of filtering and trimming each fastq. 

*These parameters are flexible and should depend on your data!*

```{r filter_bad_reads2}
demo_good_proper <- filterAndTrim(demo_F,
                                  demo_goodF,
                                  demo_R,
                                  demo_goodR,
                                  trimLeft = c(17, 21),
                                  truncLen = c(145, 135),
                                  maxN = 0,
                                  truncQ = 2,
                                  minQ=1,
                                  maxEE = c(2, 4),
                                  rm.phix = TRUE,
                                  n = 1e+5,
                                  compress = TRUE,
                                  verbose = TRUE)
# save the output of previous step (a summary table indicating how many reads there were for each sample before and after quality-filtering):
write.table(demo_good_proper,
            file = "Routput/demo_filteredout.txt",
            sep = "\t",
            quote = FALSE)
```




## Dereplicate sequences in each sample ##

Dereplicating the data collapses together reads that encode the same sequence this ends up saving computational time in later stages. (see section 4 https://bioconductor.org/packages/devel/bioc/vignettes/dada2/inst/doc/dada2-intro.html)
```{r dereplicate}
# The next step is to dereplicate the sequences in each sample
derep_demo_F <- derepFastq(demo_goodF,
                           n = 1e+06,
                           verbose = TRUE)
derep_demo_R <- derepFastq(demo_goodR,
                           n = 1e+06,
                           verbose = TRUE)
names(derep_demo_F) <- demo_samplenames
names(derep_demo_R) <- demo_samplenames
```


## Calculate and plot error-rates ##

Now let's calculate the error-rates (see below) for the forward and reverse sequences, plot them directly in RStudio and save to .pdf.

[see section 5 ]
(https://bioconductor.org/packages/devel/bioc/vignettes/dada2/inst/doc/dada2-intro.html)
From the dada2 vignette:

" The dada algorithm uses a parametric model of the errors introduced by PCR amplification and sequencing. Those error parameters typically vary between sequencing runs and PCR protocols, so our method provides a way to estimate those parameters from the data itself."

```{r set_seed}
# In order to make the results reproducible when carried out multiple times, we use the set.seed function.

set.seed(56456)
```

```{r error_calc}
## forward-reads:
demo_error_F <- learnErrors(derep_demo_F,
                            nbases = 1e+07,
                            randomize = TRUE,
                            MAX_CONSIST = 12,
                            multithread = TRUE,
                            verbose = TRUE)
plotErrors(demo_error_F,
           obs = TRUE,
           nominalQ = TRUE)
## and reverse-reads:
demo_error_R <- learnErrors(derep_demo_R,
                            nbases = 1e+07,
                            randomize = TRUE,
                            MAX_CONSIST = 12,
                            multithread = TRUE,
                            verbose = TRUE)
plotErrors(demo_error_R, obs = TRUE,
           nominalQ = TRUE)
```

We'll also save both plots to .pdf in our Rfigs directory for our records:
```{r error_plots, include=TRUE, echo=FALSE, warning=FALSE}
pdf("Rfigs/demo_error_F_plot.pdf",
    width = 10,
    height = 10,
    pointsize = 8)
plotErrors(demo_error_F,
           obs = TRUE,
           nominalQ = TRUE)
dev.off()
pdf("Rfigs/demo_error_R_plot.pdf",
    width = 10,
    height = 10,
    pointsize = 8)
plotErrors(demo_error_R,
           obs = TRUE,
           nominalQ = TRUE)
dev.off()
```


## Running dada2: Calculating ASVs ##

Now it is time to run the actual dada2 algorithm to determine the ASVs in the dataset.

  ** This step is run separately for forward and reverse sets of paired-end reads **

```{r running_dada2}
demo_dada_F <- dada(derep_demo_F,
                    err=demo_error_F,
                    pool = TRUE,
                    multithread = TRUE)
demo_dada_R <- dada(derep_demo_R,
                    err=demo_error_R,
                    pool = TRUE,
                    multithread = TRUE)
# Let's see how many sequence variants we have got in the forward set
demo_dada_F[[1]]
```


Next we will merge the forward and reverse sets (the paired-end reads for all our samples), and output a sequence-table of all ASVs.

```{r mergePairs}
demo_merged <- mergePairs(demo_dada_F,
                          derep_demo_F,
                          demo_dada_R,
                          derep_demo_R,
                          minOverlap = 20,
                          maxMismatch = 0,
                          verbose = TRUE)
# Let's make a sequence table of all the ASVs
demo_sequence_table <- makeSequenceTable(demo_merged,
                                         orderBy = "abundance")
# We can check the distribution of the ASVs by length
table(nchar(getSequences(demo_sequence_table)))
```

## Filtering chimeric sequences ##

```{r}
# Remove chimeric sequences
demo_nochim <- removeBimeraDenovo(demo_sequence_table,
                                  method = "consensus",
                                  minFoldParentOverAbundance = 1,
                                  verbose = TRUE,
                                  multithread = TRUE)
# Let's see how many ASVs remain after filtering chimeric sequences:
dim(demo_nochim)
# Let's see the proportion of sequences we retained after filtering for chimeric sequences:
sum(demo_nochim)/sum(demo_sequence_table)
```

Now we have completed all the filtering, trimming, cleanup etc. to arrive at our final data-set. Here we should check and record how many sequences we retained after each step.
  
  ** This test is important for trouble-shooting purposes. **

```{r}  
# Create a function to calculate reads retained
fetch_numbers <- function(a) sum(getUniques(a))
# Then apply this function to the output of each step in our pipeline to generate a counts-table of reads remaining after each step
demo_track_steps <- cbind(demo_good_proper,
                          sapply(demo_dada_F,
                                 fetch_numbers),
                          sapply(demo_dada_R,
                                 fetch_numbers),
                          sapply(demo_merged,
                                 fetch_numbers),
                          rowSums(demo_nochim))
colnames(demo_track_steps) <- c("input",
                                "filtered",
                                "denoisedF",
                                "denoisedR",
                                "merged",
                                "nochim")
rownames(demo_track_steps) <- demo_samplenames
# And save the output to a new file for our records:
write.table(demo_track_steps,
            file = "Routput/demo_filtering_steps_track.txt",
            sep = "\t",
            quote = FALSE)
```

## Assign taxonomy to all ASVs ##

We will next determine taxa present in our samples using the Silva database v.132.


dada2 helpfully maintains specially formatted databases for 3 of the most popular 16S microbiome-databases: Silva, Greengenes, and RDP (also UNITE for ITS).

We will be using the [dada2 Silva database](https://zenodo.org/record/1172783#.XcClW9VOnb1)

  *You downloaded this file to your Rdata directory previously (Rdata/Silva_db/silva_nr_v132_train_set.fa)*


```{r taxonomy}
demo_taxonomy <- assignTaxonomy(demo_nochim,
                                "Rdata/Silva_db/silva_nr_v132_train_set.fa",
                                minBoot = 80,
                                verbose = TRUE,
                                multithread = TRUE)
write.table(demo_taxonomy,file = "Routput/demo_taxaout.txt",
            sep = "\t",
            quote = FALSE)
```

Now we will generate output-files critical for further analyses and data-visualization. These include:

    a table summarizing ASVs by taxa
    a fasta-file of all ASVs
    a table of ASV-counts per sample (the OTU-table)

```{r make_final_tables}    
# Let's create a table by replacing the ASV sequences with ids (ASV_1, ASV_2 etc.) and their corresponding classifications
demo_taxa_summary <- demo_taxonomy
row.names(demo_taxa_summary) <- NULL
head(demo_taxa_summary)
# Let's make a file listing all the ASVs and their sequences in fasta format
demo_asv_seqs <- colnames(demo_nochim)
demo_asv_headers <- vector(dim(demo_nochim)[2],
                           mode = "character")
for (i in 1:dim(demo_nochim)[2]) {demo_asv_headers[i] <- paste(">ASV",
                                                               i,
                                                               sep = "_")}
demo_asv.fasta <- c(rbind(demo_asv_headers,
                          demo_asv_seqs))
write(demo_asv.fasta,
      file = "Routput/demo_out_asv.fasta")
# At this step, we need to make a table of ASV counts for each sample (which is going to be most important for all statistical analyses)
demo_asv_tab <- t(demo_nochim)
row.names(demo_asv_tab) <- sub(">",
                               "",
                               demo_asv_headers)
write.table(demo_asv_tab,
            file = "Routput/demo_asv_counts.tsv",
            sep = "\t",
            quote=FALSE,
            col.names = NA)
# Finally, let's make a table with the taxonomy of all the ASVs
demo_asv_taxa <- demo_taxonomy
row.names(demo_asv_taxa) <- sub(">",
                                "",
                                demo_asv_headers)
write.table(demo_asv_taxa,file = "Routput/demo_asvs_taxonomy.tsv",
            sep = "\t",
            quote=FALSE,
            col.names = NA)
dim(demo_asv_taxa)
# We'll also need to make fake sample-bmi data for tomorrow's visualization-exercises (phyloseq)
bmi <- c('obese',
         'obese',
         'lean',
         'lean')
demo_fake_sample_data <- data.frame(bmi_group=bmi)
rownames(demo_fake_sample_data) <- c("demo1",
                                     "demo2",
                                     "demo3",
                                     "demo4")
write.table(demo_fake_sample_data,
            file = "Routput/made_up_sample_data.tsv",
            sep="\t",
            quote=FALSE)
```


Tomorrow, we'll plot the data we analyzed today.


## ** End Day 2 ** ##

**USF Omics Hub Microbiome Workshop Day 3: Visualizing microbiome-data**

# Phyloseq object creation from dada2 data

We'll first be plotting the example-data we analyzed yesterday. We've started a new project for day3 of the workshop, and you'll notice the directory structure is the same as the project we set up yesterday. Your "Rdata"" folder contains the output-data from yesterday we need for plotting.

```{r setup}
source(here::here("Rsource/Hub_microbiome_workshop_source.R"))
  library(microbiome)
  library(ggplot2)
  library(ggpubr)
  library(knitr)

```
####Create a phyloseq object from DADA2 output####
```{r phyloseq-create}
infile_asv_counts<-here::here("Rdata/demo_asv_counts.tsv")
infile_asv_tax<-here::here("Rdata/demo_asvs_taxonomy.tsv")
infile_sample_data<-here::here("Rdata/made_up_sample_data.tsv")

df_asv_counts<-read.delim(infile_asv_counts)
df_asv_tax<-read.delim(infile_asv_tax)
df_sample_data<-read.delim(infile_sample_data)
#Convert the data to matrix format
m_asv_counts<-as.matrix(df_asv_counts[2:length(df_asv_counts)])
rownames(m_asv_counts)<-df_asv_counts[,1]

m_asv_tax<-as.matrix(df_asv_tax[2:length(df_asv_tax)])
rownames(m_asv_tax)<-df_asv_tax[,1]

##There are 3 possible components to a phyloseq object: otu_table, sample_data, tax_table

pseq<-phyloseq(otu_table(m_asv_counts,taxa_are_rows = T),tax_table(m_asv_tax),sample_data(df_sample_data))


##Lets look at the data in our phyloseq object
##The functions used to create the components of a phyloseq object
##can be used to view the components of a phyloseq object
View(otu_table(pseq)@.Data)
View(microbiome::meta(pseq))
View(tax_table(pseq)@.Data)
```

####Read in a dataset with interesting results and perform some initial processing####
```{r phyloseq-create}

infile<-here::here("Rdata/otu_table.biom")
infile_meta<-here::here("Rdata/meta_data.csv")


pseq<-read_biom2phyloseq(infile,metadata.file = infile_meta)

####Let's filter out some of the samples to simplify the analysis####
pseq<-subset_samples(pseq,group_name=="Without.comp.food" & diet !="Experimental infant formula")
####Summarize data at the Genus level. Not required, but convienent####
pseq<-aggregate_taxa(pseq,level="Genus")

```

##Inspect the phyloseq object
```{r inspect-phyloseq}
  View(otu_table(pseq)@.Data)
  View(microbiome::meta(pseq)) 
  #Alternative method View(sample_data(pseq))
  View(tax_table(pseq)@.Data)

```


####Calculate alpha diversity from milk study####
##Remember alpha diversity is calculated within a sample so normalization is not neccessary
```{r "alpha diversity"}
tab<-microbiome::diversity(pseq,index="all")
kable(tab)

##Let's create a dataframe for plotting the results
df_milk_meta<-microbiome::meta(pseq)
##Add Shannon divesity data to the dataframe
df_milk_meta$Shannon<-tab$shannon

##Let's create a plot comparing the diversity between breast milk and formula
plot_div<-ggviolin(df_milk_meta,x="diet",y="Shannon",
             add="boxplot",fill="diet")
##Add stats (Wilcoxon test)
plot_div<-plot_div+stat_compare_means(comparisons = list(c("Breast milk","Standard infant formula")),
                          method="wilcox.test")
print(plot_div)

##Diversity is higher in the standard infant formula group
```

####Composition plot####
```{r composition}
##Compute the relative level for each taxa
pseq.rel<-microbiome::transform(pseq,"compositional")
##Remove rare OTUs
pseq.rel.core<-core(pseq.rel,detection = 0,prevalence = 0.5)
##aggregate taxa to the class level (so data will fit on graph)
pseq.rel.core.family<-aggregate_taxa(pseq.rel.core,level="Family")

##Recommend to save as 10X10
comp_plot<-plot_composition(pseq.rel.core.family,group_by="diet")+
  guides(fill=guide_legend(ncol=1))+
    labs(x = "Samples", y = "Relative abundance",
     title = "Relative abundance data")
print(comp_plot)
```


####Beta diversity and microbiome divergence####
```{r beta diversity}
##Result is sensitive to sample size. Recommended to subsample or bootstrap to
##avoid bias
##Rarefying data is inappropriate for differential abundance testing,
##but rarefying gives the best results when comparing sample similarity
##Calculate the divergences within the diet groups
pseq.rarefied<-rarefy_even_depth(pseq,rngseed=8675309,replace=F)

##Calculate beta diversity with respect to the median taxa
##profile for each group
b.breast_milk<-divergence(x=subset_samples(pseq.rarefied,diet=="Breast milk"),y=apply(abundances(subset_samples(pseq.rarefied,diet=="Breast milk")),1,median),method="bray")

b.formula<-divergence(x=subset_samples(pseq.rarefied,diet=="Standard infant formula"),y=apply(abundances(subset_samples(pseq.rarefied,diet=="Standard infant formula")),1,median),method="bray")


#b.formula<-divergence(subset_samples(pseq.rarefied,diet="Standard infant formula"))
boxplot(list(Breast_Milk=b.breast_milk,Formula=b.formula))
wilcox.test(x=b.breast_milk,y=b.formula,alternative = "less")
##The breast milk feed infants have more similar microbiomes to each other
##than the forumla fed infants to do each other
```

####Sample ordination####
```{r sample ordination}
library(vegan) #Perform statistics on ordination results
##Rarefying data is inappropriate for differential abundance testing,
##but rarefying gives the best results when comparing sample similarity
##Calculate the divergences within the diet groups
pseq.rarefied<-rarefy_even_depth(pseq,rngseed=8675309,replace=F)

##First lets plot the sample ordination
 ord_plot<-plot_landscape(pseq.rarefied,method="PCoA",distance = "bray",col="diet")+labs(title="PCoA/Bray-Curtis")
 print(ord_plot)
 
##We will use a PERMONVA to see if there are statistically distinguishable communties 
dist<-vegdist(t(otu_table(pseq.rarefied)),method="bray")

##Check if the variances are equal between the groups. If not assumtion for PERMOVNA not met
print(anova(betadisper(dist,microbiome::meta(pseq.rarefied)$diet)))

##For this data the assumtion is not met, but here's the code
permonva_results<-adonis(t(otu_table(pseq.rarefied))~diet,data=microbiome::meta(pseq.rarefied),
                 permutations = 100,method="bray")
print(permonva_results)

##Show coefficients for the top taxa separating the groups
permonva_result_coefs<-coefficients(permonva_results)
permonva_result_diet<-permonva_result_coefs["diet1",]

top.diet.coef<-permonva_result_diet[rev(order(abs(permonva_result_diet)))[1:5]]
par(mar=c(3,9,2,1)) #Setting margin sizes requires trial and error
barplot(sort(top.diet.coef),horiz=T,las=1,main="Top taxa")
```


####To use metagenomeSeq need to create a new data object called MRexperiment####
```{r Differential abundance analysis using metagenomeSeq}
library(metagenomeSeq)
pseq_mrexp<-phyloseq_to_metagenomeSeq(pseq)


###Keep samples with at least 1 count. Keep features with at least 30 count###
pseq_mrexp<-filterData(pseq_mrexp,present=30,depth=1)

###Normalization###
p<-cumNormStat(pseq_mrexp)
pseq_mrexp<-cumNorm(pseq_mrexp,p=p) #Calculate the scaling factors

###Create a design matrix and run statistical model###
phenotype_data<-pData(pseq_mrexp) #Get the metadata associated with this experiment

###Make breast milk the reference group (Reference is the denominator in logFC)###
phenotype_data$diet<-relevel(factor(phenotype_data$diet),"Breast milk")
##A design matrix specicies what comparisons we want to make
##For more on design matrices check this youtube video: https://www.youtube.com/watch?v=CqLGvwi-5Pc
design_matrix<-model.matrix(~1+diet,data=phenotype_data) #Can drop 1, we're just explicitly showing an intercept

feature_fit_model<-fitFeatureModel(obj=pseq_mrexp,mod=design_matrix)

###Identify the differentially abundant microbes###
taxas<-fData(pseq_mrexp)$unique
sig_taxa<-MRcoefs(feature_fit_model,adjustMethod = "fdr",alpha = 0.1,taxa=taxas)
write.csv(sig_taxa,here::here("Ranalysis/pieces/Routput/sig_taxa_table_metagenomeSeq.csv"))
####Graph the results###

##Identify the rows containing the abundance info for the significant taxa
sig_taxa_index<-which(rownames(MRcounts(pseq_mrexp)) %in% rownames(sig_taxa))
##Get the descriptions of the significant taxa
sig_taxa_desc<-rownames(MRcounts(pseq_mrexp))[sig_taxa_index]
##Find data locations for the 2 groups
classIndex<-list(Breast_milk=which(pData(pseq_mrexp)$diet=="Breast milk",arr.ind = T))
classIndex$Infant_formula<-which(pData(pseq_mrexp)=="Standard infant formula",arr.ind = T)


pdf(here::here("Ranalysis/pieces/Rfigs/sig_taxa_metagenomeSeq.pdf"))
for(i in seq(1,length(sig_taxa_index))){
  taxa_index<-sig_taxa_index[[i]]
  taxa_desc<-sig_taxa_desc[[i]]
  plotOTU(pseq_mrexp,otu=taxa_index,classIndex = classIndex,main=taxa_desc)
}

dev.off()

```

####Use DESeq2 to perform differential abundance analysis####
```{r differential abundance analysis using DESeq2}
library(DESeq2)
sample_data(pseq)$diet<-relevel(factor(sample_data(pseq)$diet), "Breast milk")

##convert data to a format used by DESeq (group by diet)
pseq.deseq<-phyloseq_to_deseq2(pseq,~diet)

##Perform normalization and differential abundance test
pseq.deseq<-DESeq(pseq.deseq,test="Wald",fitType = "parametric")

##Get and filter the results
res<-results(pseq.deseq,cooksCutoff = F,pAdjustMethod = "BH",alpha=0.1)

res<-res[complete.cases(res),] ##Remove any NA results

##Write the results to file
res_table<-cbind(as(res,"data.frame"),as(tax_table(pseq)[rownames(res),],"matrix"))
write.csv(res_table,here::here("Ranalysis/pieces/Routput/sig_taxa_table_deseq2.csv"))

##Graph the results

##Normalize the expersion data
pseq.clr<-microbiome::transform(pseq,"clr")
exp_data_clr<-abundances(pseq.clr)

##Keep only the differentially abundant microbes
exp_data_clr_sig<-exp_data_clr[which(rownames(exp_data_clr) %in% rownames(res)),]
exp_data_clr_sig<-melt(exp_data_clr_sig)
colnames(exp_data_clr_sig)<-c("Taxa","Sample","CLR")

##Extract the  metadata
df_meta<-microbiome::meta(pseq.clr)
df_meta$Sample<-rownames(df_meta)
df_meta<-df_meta %>% dplyr::select(Sample,diet)

df_dam<-left_join(exp_data_clr_sig,df_meta,by="Sample")

##Create the graphs
pdf(here::here("Ranalysis/pieces/Rfigs/graph_deseq2_sig.pdf"))
for(taxon in unique(df_dam$Taxa)){

  df_dam_taxon<-df_dam %>% filter(Taxa==taxon)
  plot<-ggplot(df_dam_taxon,aes(x=diet,y=CLR))+geom_dotplot(binaxis = "y",stackdir = "center")
  plot<-plot+ggtitle(taxon)+theme(plot.title = element_text(hjust=0.5))
  print(plot)
}
dev.off()


##Normalize the expersion data
pseq.norm<-microbiome::transform(pseq,"compositional")
exp_data_norm<-abundances(pseq.norm)

##Keep only the differentially abundant microbes
exp_data_norm_sig<-exp_data_norm[which(rownames(exp_data_norm) %in% rownames(res)),]
exp_data_norm_sig<-melt(exp_data_norm_sig)
colnames(exp_data_norm_sig)<-c("Taxa","Sample","Relative_Abundance")

##Extract the  metadata
df_meta<-microbiome::meta(pseq.norm)
df_meta$Sample<-rownames(df_meta)
df_meta<-df_meta %>% dplyr::select(Sample,diet)

df_dam<-left_join(exp_data_norm_sig,df_meta,by="Sample")

##Create the graphs
pdf(here::here("Ranalysis/pieces/Rfigs/graph_deseq2_sig_ra.pdf"))
for(taxon in unique(df_dam$Taxa)){
  
  df_dam_taxon<-df_dam %>% filter(Taxa==taxon)
  plot<-ggplot(df_dam_taxon,aes(x=diet,y=Relative_Abundance))+geom_dotplot(binaxis = "y",stackdir = "center")
  plot<-plot+ggtitle(taxon)+theme(plot.title = element_text(hjust=0.5))
  print(plot)
}
dev.off()
```
```
## ** End Day 3 part I **


## USF Omics Hub Microbiome Workshop Day 3 Part II: Functional analyses 

So far, we've characterized several aspects of community-composition and made comparisons between samples. These descriptive studies are an important first step of microbiome data-analyses; they stop short of delivering meaningful *functional* data however, such as the biological pathways active in these communities, the products of which may be actual drivers of our phenotypes of interest (e.g., obese vs. lean). 

16S data is inherently limited for assessing function, but we can extrapolate some information using phylogenetic tools. In our next session, we'll be using our output differential abundance table ("Routput/differential_taxa_abundance.csv") to extrapolate functional data.

*** For logistical purposes (because the software required for this part is linux-based, not R), we've run PICRUSt2 on our output data already for you. We've provided the commands we used below. We can advise you in more detail should you need to run these steps for your own work.***
# Introduction for analyzing Picrust2 in a statistical framework

Basics of this are sort of light in the official Aldex tutorial, which frames in the more general RNAseq/whatever. Which, according to their philosphy, should work the same way. 

Basically, the Aldex way says that everything counts should be scaled relative (even rnaseq), and then you can use some abundance methods they developed to do comparative testing. 

The fast and easy ways are essentially t-tests for 2 factor designs, etc.

The full on, fully modeled way is using a glm, which is apparently quite slow, but lets the variable tested be multivariate. It tests in a one-against-all fashion if I remember correctly (link to docs)

The code to confirm the logic of hooking up the picrust2 outputs (and which) to the aldex come from

https://github.com/gavinmdouglas/picrust2_manuscript/blob/master/scripts/analyses/hmp2/hmp2_aldex2_disease_state_and_enriched.R

take the normalized pathway abundance file (seqtab_norm.tsv?)



to run:

```{bash,eval=FALSE}
source activate picrust2
# JO: most people will need to use "conda activate picrust2"

#the default output uses less memory, but outputs in a long format
#we would have to spread the data to get it back to wide (like an otu table)
#time picrust2_pipeline.py -s seqs.fna -i table.biom -o picrust_ex -p 10 --per_sequence_contrib --stratified --coverage

#add --wide-table so you don't have to spread from the data
time picrust2_pipeline.py -s seqs.fna -i table.biom -o picrust_ex -p 10 --per_sequence_contrib --stratified --coverage --wide_table
```
Note! the stratified tables, which are what we want, will increase the run time and outputfile size considerably (since they are the full ASV matrices)


https://github.com/chrismitbiz/metagenomepredictionanalysis/blob/master/16smetagenomepredanalysis.Rmd


see here to get to the RDS used later on by the picrust2 MS
https://github.com/gavinmdouglas/picrust2_manuscript/blob/4f6eaf92333d2f4e3982501f41eaa2f900f91d28/scripts/analyses/hmp2/hmp2_prep_input.R

also:

https://rpubs.com/chrisLaTrobe/Picrust_PCA_KEGG

though the aldex code results are elided

# preprocessing data for aldex

The main things to do are to drop out the pathway/sequence columns, merge them into rownames. You only need to do this with the stratified data (which splits out the effect of pathway X otu).

Unstratified looks at a whole-pathway level, so is more summarised.

General note, I prefer using readr to read in data, but we need to convert all the data from tibbles to dataframes to properly use the rownames. They have a habit of getting dropped if the tibble is modified.

```{r preproc}
library(ALDEx2)
library(readr)
library(dplyr)
#wide file?
#this is taken from the prep_input code
df=read_tsv("../Rdata/picrust_ex/pathways_out/path_abun_strat.tsv")
dfs=as.data.frame(df)
rownames(dfs)=paste(df$pathway,df$sequence,sep="|")
dfs=dfs[,-which(colnames(dfs) %in% c("pathway","sequence"))]
dfout=as.data.frame(df)

dfus=read_tsv("../Rdata/picrust_ex/pathways_out/path_abun_unstrat.tsv")
dfus=as.data.frame(dfus)
rownames(dfus)=dfus$pathway
dfus=dfus[,-which(colnames(dfus)=="pathway")]

#nothing in the pathway, look in the kegg?

dfk=read_tsv("../Rdata/picrust_ex/KO_metagenome_out/pred_metagenome_unstrat.tsv")
dfk=as.data.frame(dfk)
rownames(dfk)=dfk$`function`
dfk=dfk[,-which(colnames(dfk)=="function")]


rownames(dfout)=paste(dfout$pathway,dfout$sequence,sep="|")
dfout=dfout[,-which(colnames(dfout) %in% c("pathway","sequence"))]
df_tmp= df[, -which(colnames(df) == "sequence")]
df_abun=aggregate(.~pathway,data=df_tmp,FUN=sum)
rownames(df_abun)=df_abun$pathway
df_abun=df_abun[,-which(colnames(df_abun)=="pathway")]
#convert to relative abundance
df_rabun=data.frame(sweep(df_abun,2,colSums(df_abun),"/"),check.names=F)
# asin transformation
asinT=function(x) asin(sqrt(x))
df_rabun2=df_rabun %>% mutate_all(asinT)

#finally, round them so they
df_rrabun=round(df_rabun)




```

# exploratory analyses with phyloseq/pca

Before we go into the real-deal modeling, lets quickly check if the kegg/pathways cluster by strain or facility. We get to see the null results in real time. 
  ## JO: more explanation about why this is the first thing to check

The picrust2 notes that the example data is "greatly simplified" for the picrust2 demo, presumably mainly on the amount of metadata.

The preprint for the paper states what we will shortly show. https://peerj.com/articles/5494/

A lot of this code is directly from
https://rpubs.com/chrisLaTrobe/Picrust_PCA_KEGG

Thanks Chris LaTrobe!

```{r pca}
library(phyloseq)
library(microbiome)

mdata=read_tsv("../Rdata/metadata.tsv")
kotu=otu_table(dfk,taxa_are_rows=TRUE)
md=as.data.frame(mdata)
rownames(md)=mdata$SampleID
md=md[,-which(colnames(md)=="SampleID")]
md=sample_data(md)
kegg=phyloseq(kotu,md)
pwo=otu_table(dfout,taxa_are_rows=TRUE)
pw=phyloseq(pwo,md)

#kegg is the kegg table
#pw is the pathway table (much higher level)


pw_clr=microbiome::transform(pw,"clr")
kegg_clr=microbiome::transform(kegg,"clr")


```

# basic ordination of kegg/pathway data

Ordination / dimension reduction is basically the same as when done with regular phyloseq and "regular" OTU tables. Only thing different is that you aren't working with a taxa table.

```{r ord}
#rda is one of many ordination methods
ord_pw=phyloseq::ordinate(pw_clr,"RDA")
ord_kegg=phyloseq::ordinate(kegg_clr,"RDA")

#get the top eigenvalues of the first few PC axes
head(ord_pw$CA$eig)
#transform to percent
sapply(ord_pw$CA$eig[1:8], function(x) x / sum(ord_pw$CA$eig))
sapply(ord_kegg$CA$eig[1:8], function(x) x / sum(ord_kegg$CA$eig))
#ok, so most variation is in the first 2 axes for pathway
# 3-4 axes for kegg

p=plot_ordination(pw,ord_pw,type="samples",color="Facility",shape="Genotype")
p=p+geom_polygon(aes(fill=Genotype))
#much larger separation by Facility, genotype seems to overlap




```

# fancy-pants statistical modeling with Aldex2

Aldex2 provides a way to model compositional (count) data, using a Welch test or Kruskal-Wallis for simple comparisons (two types), and a full blown general linear model *(glm)* for multiple variables at the same time (though I ran into issues getting the effect-size and plotting). 

The other key thing to note is that picrust2 outputs fractional counts, so some rounding needs to be done or most of these programs will break.

If you have continuous metadata, you can use the aldex.corr function. For categorical data, use aldex

The aldex function performs 3 steps:

    1. some MC to get a sense of the Dirichlet distribution and then convert using a center-log transform.
    2. aldex.ttest (or aldex.kw, aldex.glm) to test for differences.
    3. aldex.effect to get effect sizes for the rows

In the first plots, you'll see nothing is significant (no red dots).

When we redo the plots by Facility, lots of things are significant. Looking back at the paper, there's an inherent Facility/Strain batch-effect that isn't possible to unravel (all samples of a strain (KO and WT) were sequenced at the same facility).

A reminder that its probably worth it to talk to someone about your design before you actually sequence/do the experiment.

```{r aldex}


conds=mdata$Genotype
#kegg
x.kf=aldex(round(dfk),conds,effects=T,denom="all")
#unstratified pathway
x.pwu=aldex(round(dfus),conds,effects=TRUE,denom="all")
#stratified pathway
x.pws=aldex(round(dfs),conds,effects=TRUE)
#x.all=aldex(round(dfs),conds,effects=TRUE)
#x.all <- aldex(selex.sub,conds,mc.samples=16,test="t",effect=TRUE,include.samples.summary=FALSE,demon="all",verbose=FALSE)

par(mfrow=(c(3,2)))
aldex.plot(x.kf,type="MA",test="welch",xlab="Log-ratio abundance",
           ylab="Difference")
aldex.plot(x.kf,type="MW",test="welch",xlab="Dispersion",
           ylab="Difference")

aldex.plot(x.pwu,type="MA",test="welch",xlab="Log-ratio abundance",
           ylab="Difference")
aldex.plot(x.pwu,type="MW",test="welch",xlab="Dispersion",
           ylab="Difference")


aldex.plot(x.pwu,type="MA",test="welch",xlab="Log-ratio abundance",
           ylab="Difference")
aldex.plot(x.pwu,type="MW",test="welch",xlab="Dispersion",
           ylab="Difference")
#nothing is significant

#redo with conds=facility
conds=mdata$Facility
x.kf=aldex(round(dfk),conds,effects=T)
x.pwu=aldex(round(dfus),conds,effects=T)
x.pws=aldex(round(dfs),conds,effects=T)

par(mfrow=(c(3,2)))
aldex.plot(x.kf,type="MA",test="welch",xlab="Log-ratio abundance",
           ylab="Difference")
aldex.plot(x.kf,type="MW",test="welch",xlab="Dispersion",
           ylab="Difference")

aldex.plot(x.pwu,type="MA",test="welch",xlab="Log-ratio abundance",
           ylab="Difference")
aldex.plot(x.pwu,type="MW",test="welch",xlab="Dispersion",
           ylab="Difference")


aldex.plot(x.pwu,type="MA",test="welch",xlab="Log-ratio abundance",
           ylab="Difference")
aldex.plot(x.pwu,type="MW",test="welch",xlab="Dispersion",
           ylab="Difference")




```


# glm model for multivariate (not quite working)

Here is the general framework for doing analyses with a glm. Note that it takes much longer than the other tests, (<1 minute for 2 variable vs 10+ minutes for glm).

Also, the output doesn't properly work with the aldex.plot and aldex.effect

To build the markdown I prevented the following chunk from running

digging in a little more, could probably do the plotting etc using the data from summary(x) (the result from the aldex.clr call)

Left column has standard MA-style plots, right column is an MW plot, which is the difference between to variance within

```{r glm,eval=FALSE}
dm=model.matrix(~Genotype+Facility,mdata)
#can do complex models with multiple terms with glm
#it is SLOWWWWW
#for this smallish dataset, it took 10+ minutes
x=aldex.clr(round(dfk),dm,denom="all")

NOT RUN, aldex.glm
#x.glm=aldex.glm(x,dm)
#x.eff=aldex.effect(x)

#par(mfrow=(c(1,2)))
#plot(x.glm[,"model.GenotypeWT Pr(>|t|).BH"], x.all$we.eBH, log="xy",xlab="glm model Genotype", ylab="Welch's t-test")
#plot(glm.test[,"model.FacilityPaloAlto Pr(>|t|).BH"], x.all$we.eBH, log="xy",xlab="glm model Facility", ylab="Welch's t-test")
```



